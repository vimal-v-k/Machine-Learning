{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abf4cf98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-07 14:17:24.253995: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-11-07 14:17:24.254031: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f37fe91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train,y_train),(x_valid,y_valid) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4cee70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train =x_train.reshape(60000,784).astype('float32')\n",
    "x_valid =x_valid.reshape(10000,784).astype('float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9b49e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train /=255\n",
    "x_valid /=255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac98084e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.32941177, 0.7254902 , 0.62352943,\n",
       "       0.5921569 , 0.23529412, 0.14117648, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.87058824, 0.99607843, 0.99607843, 0.99607843, 0.99607843,\n",
       "       0.94509804, 0.7764706 , 0.7764706 , 0.7764706 , 0.7764706 ,\n",
       "       0.7764706 , 0.7764706 , 0.7764706 , 0.7764706 , 0.6666667 ,\n",
       "       0.20392157, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.2627451 , 0.44705883,\n",
       "       0.28235295, 0.44705883, 0.6392157 , 0.8901961 , 0.99607843,\n",
       "       0.88235295, 0.99607843, 0.99607843, 0.99607843, 0.98039216,\n",
       "       0.8980392 , 0.99607843, 0.99607843, 0.54901963, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.06666667, 0.25882354, 0.05490196, 0.2627451 ,\n",
       "       0.2627451 , 0.2627451 , 0.23137255, 0.08235294, 0.9254902 ,\n",
       "       0.99607843, 0.41568628, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.3254902 , 0.99215686, 0.81960785, 0.07058824,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.08627451, 0.9137255 ,\n",
       "       1.        , 0.3254902 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.5058824 , 0.99607843, 0.93333334, 0.17254902,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.23137255, 0.9764706 ,\n",
       "       0.99607843, 0.24313726, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.52156866, 0.99607843, 0.73333335, 0.01960784,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.03529412, 0.8039216 ,\n",
       "       0.972549  , 0.22745098, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.49411765, 0.99607843, 0.7137255 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.29411766, 0.9843137 ,\n",
       "       0.9411765 , 0.22352941, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.07450981, 0.8666667 , 0.99607843, 0.6509804 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.01176471, 0.79607844, 0.99607843,\n",
       "       0.85882354, 0.13725491, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.14901961, 0.99607843, 0.99607843, 0.3019608 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.12156863, 0.8784314 , 0.99607843,\n",
       "       0.4509804 , 0.00392157, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.52156866, 0.99607843, 0.99607843, 0.20392157, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.23921569, 0.9490196 , 0.99607843,\n",
       "       0.99607843, 0.20392157, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.4745098 , 0.99607843, 0.99607843, 0.85882354, 0.15686275,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.4745098 , 0.99607843,\n",
       "       0.8117647 , 0.07058824, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        ], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_valid[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef47bc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import utils as np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ba2a58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classess = 10\n",
    "\n",
    "y_train = keras.utils.np_utils.to_categorical(y_train,n_classess)\n",
    "y_valid = keras.utils.np_utils.to_categorical(y_valid,n_classess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0117b003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e24690b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-07 14:17:50.953293: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-11-07 14:17:50.953327: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-11-07 14:17:50.953349: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (jupyterhub): /proc/driver/nvidia/version does not exist\n",
      "2022-11-07 14:17:51.012421: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67ad3fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(64,activation='sigmoid',input_shape=(784,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e5c51e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(10,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02a773ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 64)                50240     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50,890\n",
      "Trainable params: 50,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f029ca53",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error',optimizer=SGD(learning_rate=0.01),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b253ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-07 14:17:59.222866: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 188160000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0920 - accuracy: 0.0974\n",
      "Epoch 2/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0913 - accuracy: 0.1252\n",
      "Epoch 3/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0908 - accuracy: 0.1572\n",
      "Epoch 4/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0904 - accuracy: 0.1806\n",
      "Epoch 5/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0900 - accuracy: 0.2037\n",
      "Epoch 6/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0897 - accuracy: 0.2225\n",
      "Epoch 7/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0894 - accuracy: 0.2388\n",
      "Epoch 8/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0891 - accuracy: 0.2539\n",
      "Epoch 9/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0888 - accuracy: 0.2670\n",
      "Epoch 10/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0886 - accuracy: 0.2770\n",
      "Epoch 11/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0883 - accuracy: 0.2879\n",
      "Epoch 12/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0880 - accuracy: 0.3064\n",
      "Epoch 13/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0878 - accuracy: 0.3343\n",
      "Epoch 14/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0875 - accuracy: 0.3571\n",
      "Epoch 15/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0872 - accuracy: 0.3701\n",
      "Epoch 16/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0869 - accuracy: 0.3748\n",
      "Epoch 17/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0866 - accuracy: 0.3771\n",
      "Epoch 18/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0863 - accuracy: 0.3783\n",
      "Epoch 19/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0860 - accuracy: 0.3783\n",
      "Epoch 20/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0857 - accuracy: 0.3760\n",
      "Epoch 21/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0854 - accuracy: 0.3749\n",
      "Epoch 22/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0851 - accuracy: 0.3749\n",
      "Epoch 23/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0847 - accuracy: 0.3742\n",
      "Epoch 24/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0844 - accuracy: 0.3732\n",
      "Epoch 25/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0840 - accuracy: 0.3745\n",
      "Epoch 26/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0836 - accuracy: 0.3768\n",
      "Epoch 27/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0833 - accuracy: 0.3783\n",
      "Epoch 28/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0829 - accuracy: 0.3806\n",
      "Epoch 29/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0825 - accuracy: 0.3834\n",
      "Epoch 30/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0821 - accuracy: 0.3869\n",
      "Epoch 31/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0817 - accuracy: 0.3910\n",
      "Epoch 32/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0812 - accuracy: 0.3949\n",
      "Epoch 33/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0808 - accuracy: 0.4001\n",
      "Epoch 34/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0804 - accuracy: 0.4040\n",
      "Epoch 35/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0799 - accuracy: 0.4099\n",
      "Epoch 36/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0795 - accuracy: 0.4167\n",
      "Epoch 37/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0791 - accuracy: 0.4211\n",
      "Epoch 38/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0786 - accuracy: 0.4269\n",
      "Epoch 39/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0781 - accuracy: 0.4336\n",
      "Epoch 40/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0777 - accuracy: 0.4407\n",
      "Epoch 41/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0772 - accuracy: 0.4465\n",
      "Epoch 42/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0767 - accuracy: 0.4536\n",
      "Epoch 43/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0763 - accuracy: 0.4604\n",
      "Epoch 44/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0758 - accuracy: 0.4671\n",
      "Epoch 45/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0753 - accuracy: 0.4736\n",
      "Epoch 46/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0749 - accuracy: 0.4801\n",
      "Epoch 47/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0744 - accuracy: 0.4859\n",
      "Epoch 48/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0739 - accuracy: 0.4928\n",
      "Epoch 49/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0734 - accuracy: 0.5002\n",
      "Epoch 50/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0730 - accuracy: 0.5056\n",
      "Epoch 51/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0725 - accuracy: 0.5124\n",
      "Epoch 52/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0720 - accuracy: 0.5179\n",
      "Epoch 53/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0715 - accuracy: 0.5240\n",
      "Epoch 54/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0711 - accuracy: 0.5288\n",
      "Epoch 55/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0706 - accuracy: 0.5341\n",
      "Epoch 56/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0701 - accuracy: 0.5409\n",
      "Epoch 57/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0696 - accuracy: 0.5455\n",
      "Epoch 58/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0692 - accuracy: 0.5502\n",
      "Epoch 59/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0687 - accuracy: 0.5548\n",
      "Epoch 60/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0682 - accuracy: 0.5598\n",
      "Epoch 61/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0678 - accuracy: 0.5638\n",
      "Epoch 62/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0673 - accuracy: 0.5677\n",
      "Epoch 63/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0668 - accuracy: 0.5715\n",
      "Epoch 64/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0664 - accuracy: 0.5760\n",
      "Epoch 65/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0659 - accuracy: 0.5792\n",
      "Epoch 66/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0654 - accuracy: 0.5836\n",
      "Epoch 67/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0650 - accuracy: 0.5871\n",
      "Epoch 68/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0645 - accuracy: 0.5906\n",
      "Epoch 69/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0641 - accuracy: 0.5935\n",
      "Epoch 70/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0636 - accuracy: 0.5969\n",
      "Epoch 71/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0632 - accuracy: 0.6002\n",
      "Epoch 72/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0627 - accuracy: 0.6033\n",
      "Epoch 73/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0623 - accuracy: 0.6066\n",
      "Epoch 74/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0619 - accuracy: 0.6099\n",
      "Epoch 75/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0614 - accuracy: 0.6133\n",
      "Epoch 76/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0610 - accuracy: 0.6161\n",
      "Epoch 77/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0606 - accuracy: 0.6192\n",
      "Epoch 78/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0601 - accuracy: 0.6218\n",
      "Epoch 79/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0597 - accuracy: 0.6250\n",
      "Epoch 80/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0593 - accuracy: 0.6276\n",
      "Epoch 81/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0589 - accuracy: 0.6312\n",
      "Epoch 82/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0585 - accuracy: 0.6336\n",
      "Epoch 83/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0581 - accuracy: 0.6362\n",
      "Epoch 84/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0577 - accuracy: 0.6393\n",
      "Epoch 85/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0573 - accuracy: 0.6421\n",
      "Epoch 86/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0569 - accuracy: 0.6450\n",
      "Epoch 87/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0565 - accuracy: 0.6479\n",
      "Epoch 88/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0561 - accuracy: 0.6510\n",
      "Epoch 89/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0557 - accuracy: 0.6546\n",
      "Epoch 90/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0553 - accuracy: 0.6575\n",
      "Epoch 91/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0549 - accuracy: 0.6602\n",
      "Epoch 92/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0546 - accuracy: 0.6636\n",
      "Epoch 93/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0542 - accuracy: 0.6663\n",
      "Epoch 94/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0538 - accuracy: 0.6686\n",
      "Epoch 95/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0535 - accuracy: 0.6721\n",
      "Epoch 96/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0531 - accuracy: 0.6754\n",
      "Epoch 97/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0528 - accuracy: 0.6779\n",
      "Epoch 98/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0524 - accuracy: 0.6805\n",
      "Epoch 99/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0521 - accuracy: 0.6835\n",
      "Epoch 100/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0517 - accuracy: 0.6865\n",
      "Epoch 101/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0514 - accuracy: 0.6890\n",
      "Epoch 102/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0510 - accuracy: 0.6917\n",
      "Epoch 103/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0507 - accuracy: 0.6949\n",
      "Epoch 104/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0504 - accuracy: 0.6982\n",
      "Epoch 105/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0500 - accuracy: 0.7008\n",
      "Epoch 106/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0497 - accuracy: 0.7034\n",
      "Epoch 107/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0494 - accuracy: 0.7064\n",
      "Epoch 108/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0491 - accuracy: 0.7093\n",
      "Epoch 109/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0488 - accuracy: 0.7113\n",
      "Epoch 110/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0485 - accuracy: 0.7147\n",
      "Epoch 111/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0482 - accuracy: 0.7170\n",
      "Epoch 112/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0479 - accuracy: 0.7195\n",
      "Epoch 113/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0476 - accuracy: 0.7220\n",
      "Epoch 114/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0473 - accuracy: 0.7244\n",
      "Epoch 115/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0470 - accuracy: 0.7268\n",
      "Epoch 116/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0467 - accuracy: 0.7291\n",
      "Epoch 117/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0464 - accuracy: 0.7317\n",
      "Epoch 118/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0461 - accuracy: 0.7331\n",
      "Epoch 119/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0458 - accuracy: 0.7352\n",
      "Epoch 120/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0456 - accuracy: 0.7375\n",
      "Epoch 121/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0453 - accuracy: 0.7403\n",
      "Epoch 122/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0450 - accuracy: 0.7419\n",
      "Epoch 123/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0448 - accuracy: 0.7441\n",
      "Epoch 124/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0445 - accuracy: 0.7459\n",
      "Epoch 125/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0442 - accuracy: 0.7475\n",
      "Epoch 126/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0440 - accuracy: 0.7491\n",
      "Epoch 127/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0437 - accuracy: 0.7506\n",
      "Epoch 128/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0435 - accuracy: 0.7523\n",
      "Epoch 129/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0432 - accuracy: 0.7543\n",
      "Epoch 130/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0430 - accuracy: 0.7560\n",
      "Epoch 131/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0427 - accuracy: 0.7582\n",
      "Epoch 132/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0425 - accuracy: 0.7595\n",
      "Epoch 133/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0422 - accuracy: 0.7614\n",
      "Epoch 134/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0420 - accuracy: 0.7629\n",
      "Epoch 135/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0418 - accuracy: 0.7645\n",
      "Epoch 136/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0415 - accuracy: 0.7661\n",
      "Epoch 137/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0413 - accuracy: 0.7676\n",
      "Epoch 138/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0411 - accuracy: 0.7692\n",
      "Epoch 139/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0408 - accuracy: 0.7707\n",
      "Epoch 140/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0406 - accuracy: 0.7726\n",
      "Epoch 141/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0404 - accuracy: 0.7740\n",
      "Epoch 142/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0402 - accuracy: 0.7760\n",
      "Epoch 143/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0399 - accuracy: 0.7779\n",
      "Epoch 144/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0397 - accuracy: 0.7792\n",
      "Epoch 145/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0395 - accuracy: 0.7807\n",
      "Epoch 146/150\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.0393 - accuracy: 0.78 - 1s 3ms/step - loss: 0.0393 - accuracy: 0.7830\n",
      "Epoch 147/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0391 - accuracy: 0.7845\n",
      "Epoch 148/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0389 - accuracy: 0.7863\n",
      "Epoch 149/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0387 - accuracy: 0.7880\n",
      "Epoch 150/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0385 - accuracy: 0.7898\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(x_train,y_train,batch_size=128,epochs=150,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f53b8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "473c33f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = fetch_openml(data_id=1464, return_X_y=True)\n",
    "X_train, X_valid, Y_train,Y_valid = train_test_split(X, Y, stratify=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "974b963e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('logisticregression', LogisticRegression(random_state=0))])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = make_pipeline(StandardScaler(), LogisticRegression(random_state=0))\n",
    "clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "04998f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "67610f4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y_pred = clf.predict(X_valid)\n",
    "cm = confusion_matrix(Y_valid, Y_pred)\n",
    "cm_display = ConfusionMatrixDisplay(cm).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6093db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
